{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62537906",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This project aims to predict the outcomes of English Premier League (EPL) soccer/football matches using deep learning techniques from class.\n",
    "\n",
    "https://github.com/nich5850/DeepLearningFinal\n",
    "\n",
    "**Motivation:**  \n",
    "I watch and play soccer all the time. The thing is soccer outcome prediction is a challenging task because of how many features go into each game. It's useful for fans, analysts, betting markets, and clubs. This project investigates whether engineered features from historical match data can help classify match results.\n",
    "\n",
    "**Approach:**  \n",
    "I engineered features like form, past performance, and relative stats, then trained two models:\n",
    "1. Random Forest Classifier — for interpretability\n",
    "2. MLP Classifier — for capturing non-linear patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87cbb2",
   "metadata": {},
   "source": [
    "# 2. Dataset\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "I use a cleaned dataset `final_dataset.csv` that contains a ton of data about pre-match stats and match outcomes. Here's how the dataset is loaded and previewed:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n",
    "```\n",
    "\n",
    "### Target Variable\n",
    "\n",
    "I then added a `ResultLabel` column to represent the match outcome:\n",
    "- 0: Home Win\n",
    "- 1: Away Win\n",
    "- 2: Draw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52459c1",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning and EDA\n",
    "\n",
    "I removed columns that would cause data leakage or were irrelevant for modeling.\n",
    "\n",
    "### Data Transformation Considerations\n",
    "Some features had different ranges (e.g., `FormPts` ranges from 0–15, while `GoalDiff` could be much larger).\n",
    "\n",
    "- For Random Forest I did not standardize features before RF training because I know this isn't scale dependent. \n",
    "- However, the MLP model is sensitive to feature scales, so I applied `StandardScaler` to the features before MLP training.\n",
    "\n",
    "### Missing Data & Cleaning\n",
    "- The dataset was preprocessed to remove rows with missing values.\n",
    "  \n",
    "### Important Feature Hypotheses\n",
    "Based on basic knowledge of soccer, I hypothesized the following features to be most predictive:\n",
    "\n",
    "- `HFormPts` and `AFormPts` — represent recent team performance  \n",
    "- `HST`, `AST` — how many shots on targets (similar to xG)  \n",
    "- `HGF`, `AGF` — season-to-date goals scored  \n",
    "\n",
    "These hypotheses were later validated during feature importance analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Cleaning Code Snippet\n",
    "\n",
    "```python\n",
    "# Drop columns that reveal the final score or post-match info\n",
    "leakage_cols = ['FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR']\n",
    "df.drop(columns=[col for col in leakage_cols if col in df.columns], inplace=True)\n",
    "\n",
    "# Drop identifiers and team names\n",
    "df.drop(columns=['Date', 'HomeTeam', 'AwayTeam'], inplace=True)\n",
    "\n",
    "# Drop columns that directly compute the label\n",
    "df.drop(columns=['HTP', 'ATP', 'DiffPts'], inplace=True)\n",
    "\n",
    "# Keep only numeric data\n",
    "df = df.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ffd2d7",
   "metadata": {},
   "source": [
    "# 4. Train/Test Split\n",
    "\n",
    "I split the data 80/20 using sklearn's `train_test_split`.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['ResultLabel'])\n",
    "y = df['ResultLabel']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "Shape of the resulting datasets:\n",
    "\n",
    "- `X_train`: (number of training samples, number of features)\n",
    "- `X_test`: (number of test samples, number of features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2b314",
   "metadata": {},
   "source": [
    "# 5. Random Forest Classifier\n",
    "\n",
    "### Training\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "```\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "Training Random Forest...\n",
    "\n",
    "Random Forest Evaluation:\n",
    "Accuracy: 0.8961988304093568\n",
    "Confusion Matrix:\n",
    " [[579  50   2]\n",
    " [ 63 574   0]\n",
    " [ 14  13  73]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.92      0.90       631\n",
    "           1       0.90      0.90      0.90       637\n",
    "           2       0.97      0.73      0.83       100\n",
    "\n",
    "    accuracy                           0.90      1368\n",
    "   macro avg       0.92      0.85      0.88      1368\n",
    "weighted avg       0.90      0.90      0.90      1368\n",
    "```\n",
    "\n",
    "### Feature Importances\n",
    "\n",
    "```python\n",
    "importances = rf.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "top_10 = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "Top 10 Important Features:\n",
    "        Feature  Importance\n",
    "18  DiffFormPts    0.192975\n",
    "16         HTGD    0.188572\n",
    "17         ATGD    0.179686\n",
    "6     HTFormPts    0.059762\n",
    "4          ATGC    0.059145\n",
    "7     ATFormPts    0.058501\n",
    "2          ATGS    0.057365\n",
    "1          HTGS    0.054247\n",
    "3          HTGC    0.054056\n",
    "5            MW    0.048716\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cd502",
   "metadata": {},
   "source": [
    "## Random Forest Summary\n",
    "\n",
    "- Accuracy: ~89.6%\n",
    "- Performed well across all result types\n",
    "- Most important features include form-related and attacking metrics\n",
    "- Draws were harder to predict, but not misclassified as often\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2025742",
   "metadata": {},
   "source": [
    "# 6. MLP Classifier\n",
    "\n",
    "### Training\n",
    "\n",
    "```python\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "```\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "```python\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "\n",
    "Training MLP Classifier...\n",
    "\n",
    "MLP Evaluation:\n",
    "Accuracy: 0.7785087719298246\n",
    "Confusion Matrix:\n",
    " [[617  14   0]\n",
    " [205 402  30]\n",
    " [ 48   6  46]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.71      0.98      0.82       631\n",
    "           1       0.95      0.63      0.76       637\n",
    "           2       0.61      0.46      0.52       100\n",
    "\n",
    "    accuracy                           0.78      1368\n",
    "   macro avg       0.76      0.69      0.70      1368\n",
    "weighted avg       0.81      0.78      0.77      1368\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355d343",
   "metadata": {},
   "source": [
    "## MLP Classifier Summary\n",
    "\n",
    "- Accuracy: ~77.9%\n",
    "- Performance dropped for predicting draws\n",
    "- Captured some non-linear patterns but less interpretable\n",
    "- Still outperformed random guessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c31c14",
   "metadata": {},
   "source": [
    "# 7. Discussion\n",
    "\n",
    "### Feature Impact:\n",
    "- Random Forest identified key features like `HFormPts`, `Goal Difference`, and `Shots on Target`.\n",
    "- These represent recent form and offensive capabilities — intuitive predictors of match outcome.\n",
    "\n",
    "### Model Comparison:\n",
    "- Random Forest outperformed MLP in both accuracy and interpretability.\n",
    "- MLP struggled more with predicting draws — common in sports classification tasks.\n",
    "- Adding layers could boost the accuracy drastically here.\n",
    "\n",
    "### Realism & Validity:\n",
    "- No future-dependent features or final scores were used in training.\n",
    "- My early versions of the code had a lot of data leakage so it was always returning 100% accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6ff4f",
   "metadata": {},
   "source": [
    "# 8. Conclusion\n",
    "\n",
    "### What I Learned:\n",
    "- EPL match outcome prediction is feasible using engineered pre-match features.\n",
    "- Random Forest performed well and provided interpretable insights.\n",
    "- MLP was less accurate but still showed promise.\n",
    "\n",
    "### Limitations:\n",
    "- Models do not account for injuries, weather, or lineup changes.\n",
    "- Static snapshot — no time-aware validation or rolling features.\n",
    "\n",
    "### Future Work:\n",
    "- Introduce betting odds.\n",
    "- Explore recurrent neural networks or sequence models.\n",
    "- Get way better/richer data including location, player stats, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d351b-61ca-4f2d-9368-7b2d2e713b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
